{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4545c911-e750-4f3c-bff1-9c7667945387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "EPRTools_dir=\"/Users/sylvainbertaina/Documents/Cloud_CNRS/GitHub\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "if EPRTools_dir not in sys.path:\n",
    "    sys.path.append(EPRTools_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770287ce-dade-476a-84e7-ed8ce3ff2798",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libfreetype.6.dylib\n  Referenced from: <F07DE6DC-69C0-3328-8957-035E67BF3B3D> /Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so\n  Reason: tried: '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/usr/local/lib/libfreetype.6.dylib' (no such file), '/usr/lib/libfreetype.6.dylib' (no such file, not in dyld cache)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert_to_fair.py\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meprload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mper\u001b[39;00m \u001b[38;5;66;03m# Import your library as 'per'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Cloud_CNRS/GitHub/EPyRTools/eprload.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m filedialog\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, Tuple, Optional, Union, List\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/__init__.py:264\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m    260\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 264\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/__init__.py:249\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_versions\u001b[39m():\n\u001b[1;32m    246\u001b[0m \n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# Quickfix to ensure Microsoft Visual C++ redistributable\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# DLLs are loaded before importing kiwisolver\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ft2font  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m modname, minver \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    252\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.10\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    253\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateutil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyparsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    257\u001b[0m     ]:\n\u001b[1;32m    258\u001b[0m         module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libfreetype.6.dylib\n  Referenced from: <F07DE6DC-69C0-3328-8957-035E67BF3B3D> /Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so\n  Reason: tried: '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/usr/local/lib/libfreetype.6.dylib' (no such file), '/usr/lib/libfreetype.6.dylib' (no such file, not in dyld cache)"
     ]
    }
   ],
   "source": [
    "# convert_to_fair.py\n",
    "import eprload as per # Import your library as 'per'\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "# --- Helper function to make metadata JSON serializable ---\n",
    "def make_serializable(data):\n",
    "    \"\"\"Converts numpy arrays and other non-JSON types in a dict to lists/strings.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: make_serializable(v) for k, v in data.items()}\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        return [make_serializable(item) for item in data]\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        # Check if array contains non-numeric types like objects or strings\n",
    "        if data.dtype.kind in ('O', 'S', 'U'):\n",
    "             warnings.warn(f\"Converting numpy array with dtype {data.dtype} to list. Potential data alteration for complex objects.\")\n",
    "        return data.tolist() # Convert numpy arrays to nested lists\n",
    "    elif isinstance(data, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "        return int(data)\n",
    "    elif isinstance(data, (np.float_, np.float16, np.float32, np.float64)):\n",
    "        # Handle potential NaN/Inf which are not standard JSON\n",
    "        if np.isnan(data): return 'NaN'\n",
    "        if np.isinf(data): return 'Infinity' if data > 0 else '-Infinity'\n",
    "        return float(data)\n",
    "    elif isinstance(data, (np.complex_, np.complex64, np.complex128)):\n",
    "        return {'real': make_serializable(data.real), 'imag': make_serializable(data.imag)}\n",
    "    elif isinstance(data, np.bool_):\n",
    "        return bool(data)\n",
    "    elif isinstance(data, (Path, datetime.datetime, datetime.date)):\n",
    "        return str(data) # Convert Path and datetime objects to strings\n",
    "    # Basic types that are already JSON serializable\n",
    "    elif isinstance(data, (str, int, float, bool, type(None))):\n",
    "        return data\n",
    "    else:\n",
    "        warnings.warn(f\"Data type {type(data)} is not explicitly handled for JSON serialization. Converting to string.\")\n",
    "        return str(data) # Fallback: convert unknown types to string\n",
    "\n",
    "# --- Main Conversion Function ---\n",
    "def convert_bruker_to_fair(input_path, output_dir, scaling_options=\"\"):\n",
    "    \"\"\"\n",
    "    Loads Bruker EPR data using per.eprload and saves it as CSV + JSON.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to the Bruker data file (.dta, .dsc, .spc, .par)\n",
    "                          or directory to browse.\n",
    "        output_dir (str): Directory where the FAIR CSV and JSON files will be saved.\n",
    "        scaling_options (str): Scaling string passed to per.eprload (e.g., 'nG').\n",
    "\n",
    "    Returns:\n",
    "        bool: True if conversion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to load: {input_path}\")\n",
    "    print(f\"Using scaling: '{scaling_options}'\")\n",
    "\n",
    "    try:\n",
    "        # Call your eprload function, suppressing its default plot\n",
    "        x_data, y_data, parameters, source_file_path = per.eprload(\n",
    "            input_path,\n",
    "            scaling=scaling_options,\n",
    "            plot_if_possible=False # We don't need the default plot here\n",
    "        )\n",
    "\n",
    "        # Check if loading failed (e.g., user cancel, file error)\n",
    "        if y_data is None or source_file_path is None:\n",
    "            print(f\"Failed to load data from '{input_path}'. Skipping conversion.\", file=sys.stderr)\n",
    "            return False\n",
    "\n",
    "        source_file = Path(source_file_path)\n",
    "        print(f\"Successfully loaded: {source_file.name}\")\n",
    "\n",
    "        # --- Prepare Output ---\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True) # Create output dir if needed\n",
    "\n",
    "        # Generate base filename for outputs\n",
    "        base_output_name = source_file.stem\n",
    "\n",
    "        # --- Save Data (CSV) ---\n",
    "        data_filename = output_path / f\"{base_output_name}_data.csv\"\n",
    "        print(f\"Saving data to: {data_filename}\")\n",
    "\n",
    "        if y_data.ndim == 1:\n",
    "            # 1D Data: Create a 2-column CSV (abscissa, ordinate)\n",
    "            header = \"Abscissa,Ordinate\"\n",
    "            if x_data is not None and isinstance(x_data, np.ndarray) and x_data.shape == y_data.shape:\n",
    "                # Try to get units from parameters for header (example)\n",
    "                x_unit = parameters.get('XUNI', 'a.u.')\n",
    "                if isinstance(x_unit, list): x_unit = x_unit[0] # Take first for 1D\n",
    "                y_unit = \"Intensity (a.u.)\" # Add Y unit if available in params?\n",
    "                header = f\"Abscissa ({x_unit}),Ordinate ({y_unit})\"\n",
    "                # Stack horizontally (column-wise)\n",
    "                save_data = np.vstack((x_data, y_data)).T\n",
    "            else:\n",
    "                warnings.warn(\"Abscissa data missing or incompatible. Saving ordinate data with index.\")\n",
    "                # Save ordinate only, add index column\n",
    "                header = \"Index,Ordinate (a.u.)\"\n",
    "                save_data = np.vstack((np.arange(y_data.size), y_data)).T\n",
    "\n",
    "            # Handle complex data\n",
    "            if np.iscomplexobj(save_data):\n",
    "                 # Save real and imaginary parts in separate columns\n",
    "                 header += \"_Real,Ordinate_Imag\" # Adjust header if needed\n",
    "                 real_part = save_data[:, 1].real\n",
    "                 imag_part = save_data[:, 1].imag\n",
    "                 save_data = np.vstack((save_data[:, 0].real, real_part, imag_part)).T # Keep abscissa real\n",
    "\n",
    "            np.savetxt(data_filename, save_data, delimiter=',', header=header, comments='')\n",
    "\n",
    "        elif y_data.ndim == 2:\n",
    "            # 2D Data: Save the matrix as CSV. Store axes info in metadata.\n",
    "            # Note: CSV is not ideal for large 2D data, but keeps it simple text.\n",
    "            print(\"Saving 2D data matrix. Axes details will be in the JSON metadata.\")\n",
    "            header = f\"2D Data Matrix ({y_data.shape[0]}x{y_data.shape[1]})\"\n",
    "            \n",
    "            save_matrix = y_data\n",
    "            # Handle complex 2D data: save real part only to CSV for simplicity\n",
    "            # Or save two separate files (real/imag)? Let's save real for now.\n",
    "            # Metadata will indicate if original was complex.\n",
    "            if np.iscomplexobj(save_matrix):\n",
    "                warnings.warn(\"Saving only the real part of complex 2D data to CSV.\")\n",
    "                header += \" - Real Part Only\"\n",
    "                save_matrix = save_matrix.real\n",
    "                \n",
    "            np.savetxt(data_filename, save_matrix, delimiter=',', header=header, comments='')\n",
    "\n",
    "        else:\n",
    "            print(f\"Data has {y_data.ndim} dimensions. CSV saving implemented only for 1D/2D. Skipping data save.\", file=sys.stderr)\n",
    "            # Optionally save as NPY binary format?\n",
    "            # npy_filename = output_path / f\"{base_output_name}_data.npy\"\n",
    "            # np.save(npy_filename, y_data)\n",
    "            # print(f\"Saved high-dimensional data to binary NumPy format: {npy_filename}\")\n",
    "            \n",
    "        # --- Save Metadata (JSON) ---\n",
    "        metadata_filename = output_path / f\"{base_output_name}_metadata.json\"\n",
    "        print(f\"Saving metadata to: {metadata_filename}\")\n",
    "\n",
    "        # Prepare metadata dictionary\n",
    "        fair_metadata = {\n",
    "            \"FAIR_conversion_details\": {\n",
    "                \"script_name\": Path(__file__).name,\n",
    "                \"conversion_timestamp_utc\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "                \"EPyRTools_version\": getattr(per, '__version__', 'unknown'), # Add version if EPyRTools has one\n",
    "                \"scaling_applied_by_eprload\": scaling_options,\n",
    "            },\n",
    "            \"source_data\": {\n",
    "                \"original_filename\": source_file.name,\n",
    "                \"original_full_path\": str(source_file.resolve()), # Full path for traceability\n",
    "                \"format_type_guessed_by_eprload\": parameters.get('_FormatGuess', 'unknown') # Store how eprload identified it if available\n",
    "            },\n",
    "            \"data_representation\": {\n",
    "                 \"data_file\": data_filename.name, # Relative path within the output dir\n",
    "                 \"dimensions\": y_data.shape,\n",
    "                 \"is_complex\": np.iscomplexobj(y_data).item(), # Store bool if data was complex\n",
    "                 \"axes\": []\n",
    "                 # Future: Add NPY file details here if used for >2D\n",
    "            },\n",
    "            \"original_parameters\": make_serializable(parameters) # Add the original params\n",
    "        }\n",
    "\n",
    "        # Add axes info to metadata\n",
    "        if x_data is not None:\n",
    "            if isinstance(x_data, np.ndarray) and y_data.ndim == 1:\n",
    "                x_label = parameters.get(\"XNAM\", \"Abscissa\")\n",
    "                x_unit = parameters.get(\"XUNI\", \"a.u.\")\n",
    "                fair_metadata[\"data_representation\"][\"axes\"].append({\n",
    "                    \"axis\": 0,\n",
    "                    \"name\": x_label,\n",
    "                    \"unit\": x_unit,\n",
    "                    \"data_in_file\": data_filename.name, # Indicates data is in the CSV\n",
    "                    \"column_index (1D)\": 0 # 0-based index\n",
    "                })\n",
    "            elif isinstance(x_data, list) and y_data.ndim == 2 and len(x_data) >= 2:\n",
    "                # Assume x_data = [x_axis_vec, y_axis_vec] for 2D\n",
    "                 axis_names = parameters.get(\"_AxesNames\", [\"X\", \"Y\"]) # Get from eprload/utils if available\n",
    "                 axis_units = parameters.get(\"_Abscissa_Units\", [\"a.u.\", \"a.u.\"])\n",
    "                 if not isinstance(axis_units, list): axis_units = [axis_units] * len(axis_names) # Ensure list\n",
    "\n",
    "                 # X-axis (corresponds to columns, numpy axis 1)\n",
    "                 if isinstance(x_data[0], np.ndarray) and x_data[0].size == y_data.shape[1]:\n",
    "                     fair_metadata[\"data_representation\"][\"axes\"].append({\n",
    "                        \"axis\": 1, # Numpy axis index\n",
    "                        \"name\": axis_names[0],\n",
    "                        \"unit\": axis_units[0] if len(axis_units) > 0 else \"a.u.\",\n",
    "                        \"values\": make_serializable(x_data[0]) # Embed axis values\n",
    "                     })\n",
    "                 else:\n",
    "                     warnings.warn(f\"X-axis data for 2D plot has unexpected shape/type ({type(x_data[0])}, size {getattr(x_data[0], 'size', 'N/A')}) vs data cols ({y_data.shape[1]}). Skipping X-axis metadata.\")\n",
    "\n",
    "\n",
    "                 # Y-axis (corresponds to rows, numpy axis 0)\n",
    "                 if isinstance(x_data[1], np.ndarray) and x_data[1].size == y_data.shape[0]:\n",
    "                    fair_metadata[\"data_representation\"][\"axes\"].append({\n",
    "                       \"axis\": 0, # Numpy axis index\n",
    "                       \"name\": axis_names[1] if len(axis_names) > 1 else \"Y\",\n",
    "                       \"unit\": axis_units[1] if len(axis_units) > 1 else \"a.u.\",\n",
    "                       \"values\": make_serializable(x_data[1]) # Embed axis values\n",
    "                    })\n",
    "                 else:\n",
    "                     warnings.warn(f\"Y-axis data for 2D plot has unexpected shape/type ({type(x_data[1])}, size {getattr(x_data[1], 'size', 'N/A')}) vs data rows ({y_data.shape[0]}). Skipping Y-axis metadata.\")\n",
    "            else:\n",
    "                warnings.warn(\"Format of 'x_data' is not directly usable for standard axes metadata.\")\n",
    "                fair_metadata[\"data_representation\"][\"axes\"].append({\n",
    "                     \"axis_info_raw\": f\"Type: {type(x_data)}, consult original parameters or inspect data.\"\n",
    "                })\n",
    "\n",
    "\n",
    "        # Write JSON metadata file\n",
    "        try:\n",
    "            with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(fair_metadata, f, indent=4, ensure_ascii=False)\n",
    "        except TypeError as e:\n",
    "            print(f\"\\nError: Could not serialize metadata to JSON: {e}\", file=sys.stderr)\n",
    "            print(\"This might happen if the parameters dictionary contains complex objects\", file=sys.stderr)\n",
    "            print(\"Check the output of the 'make_serializable' function warnings.\", file=sys.stderr)\n",
    "            return False\n",
    "        except Exception as e:\n",
    "             print(f\"\\nError writing JSON metadata file: {e}\", file=sys.stderr)\n",
    "             return False\n",
    "\n",
    "        print(\"Conversion successful.\")\n",
    "        return True\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Input file not found - {e}\", file=sys.stderr)\n",
    "        return False\n",
    "    except ImportError:\n",
    "        print(\"Error: Could not import the 'EPyRTools' library as 'per'.\", file=sys.stderr)\n",
    "        print(\"Please ensure EPyRTools is installed and accessible in your Python environment.\", file=sys.stderr)\n",
    "        print(\"Also check that eprload.py and its 'sub' directory are correctly placed within the EPyRTools package.\", file=sys.stderr)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred during conversion: {e}\", file=sys.stderr)\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "# --- Command Line Interface ---\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Convert Bruker EPR data (BES3T, ESP) to FAIR format (CSV data + JSON metadata).\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"input_path\",\n",
    "        help=\"Path to the Bruker data file (.dta, .dsc, .spc, .par) OR a directory to open a file browser.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\", \"--output_dir\",\n",
    "        default=\"FAIR_output\",\n",
    "        help=\"Directory to save the converted CSV and JSON files.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\", \"--scaling\",\n",
    "        default=\"\",\n",
    "        help=\"Scaling options string passed to eprload (e.g., 'nG'). See eprload documentation for details.\"\n",
    "    )\n",
    "    # Example: Add version if your package has one\n",
    "    try:\n",
    "       version = getattr(per, '__version__', 'unknown')\n",
    "       parser.add_argument('--version', action='version', version=f'%(prog)s using EPyRTools version {version}')\n",
    "    except ImportError:\n",
    "        # Handle case where per couldn't be imported even for version initially\n",
    "        pass\n",
    "    except AttributeError:\n",
    "         pass # If per doesn't have __version__\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Use Path object for input path handling\n",
    "    input_path_obj = Path(args.input_path)\n",
    "\n",
    "    if input_path_obj.is_dir():\n",
    "        # If directory, let eprload handle the file dialog via convert function\n",
    "        # We expect convert_bruker_to_fair to potentially show the dialog\n",
    "        print(f\"Input path '{args.input_path}' is a directory. eprload should open a file dialog...\")\n",
    "        success = convert_bruker_to_fair(args.input_path, args.output_dir, args.scaling)\n",
    "    elif input_path_obj.is_file():\n",
    "        # If file, proceed directly\n",
    "        success = convert_bruker_to_fair(args.input_path, args.output_dir, args.scaling)\n",
    "    elif not input_path_obj.exists():\n",
    "        # If doesn't exist, could be a path for the dialog *or* an error\n",
    "        # We pass it to eprload to decide / raise FileNotFoundError if needed\n",
    "        print(f\"Input path '{args.input_path}' does not exist. Passing to eprload (may open dialog or error out)...\")\n",
    "        success = convert_bruker_to_fair(args.input_path, args.output_dir, args.scaling)\n",
    "\n",
    "    if not success:\n",
    "        sys.exit(1) # Exit with error code if conversion failed\n",
    "    else:\n",
    "         print(\"\\nConversion process finished.\")\n",
    "         sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4745f9b9-c88e-419e-88a9-b985689cdd54",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01meprload\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully imported eprload.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Cloud_CNRS/GitHub/EPyRTools/eprload.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/__init__.py:263\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/matplotlib/__init__.py:248\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_versions\u001b[39m():\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m     \u001b[38;5;66;03m# Quickfix to ensure Microsoft Visual C++ redistributable\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;66;03m# DLLs are loaded before importing kiwisolver\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ft2font  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m modname, minver \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    251\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.10\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    252\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateutil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m             (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyparsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    256\u001b[0m     ]:\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so, 0x0002): Library not loaded: @rpath/libfreetype.6.dylib\n  Referenced from: <C39DDE61-6C7F-326D-A889-44F4C6350A70> /Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/ft2font.cpython-310-darwin.so\n  Reason: tried: '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/lib/python3.10/site-packages/matplotlib/../../../libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/Users/sylvainbertaina/miniconda3/bin/../lib/libfreetype.6.dylib' (no such file), '/usr/local/lib/libfreetype.6.dylib' (no such file), '/usr/lib/libfreetype.6.dylib' (no such file, not in dyld cache)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure eprload.py and its \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory are accessible.\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Optionally, add sys.path manipulation here if needed, but it's often better\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# to structure the project correctly or install it as a package.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#     print(\"Failed to import eprload even after path adjustment.\", file=sys.stderr)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m#     sys.exit(1)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Exit if import fails\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# --- Helper Functions ---\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_prompt_output_details\u001b[39m(source_file_path: Path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Path], Optional[\u001b[38;5;28mstr\u001b[39m]]:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb044f-a2fc-4d8d-ae39-d750ecb4dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
